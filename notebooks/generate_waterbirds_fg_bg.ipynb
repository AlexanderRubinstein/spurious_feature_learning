{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Waterbirds Original, FG-Only and BG-Only data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this notebook: https://github.com/PolinaKirichenko/deep_feature_reweighting/blob/main/notebooks/data_generation/generate_waterbirds_fg_bg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "# from pycocotools.mask import encode, decode\n",
    "\n",
    "import cv2\n",
    "\n",
    "# from detectron2.structures import BoxMode\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../group_DRO/\")\n",
    "\n",
    "# code from https://github.com/kohpangwei/group_DRO\n",
    "from dataset_scripts.dataset_utils import crop_and_resize, combine_and_mask\n",
    "sys.path.pop(0)\n",
    "\n",
    "# Change the paths below.\n",
    "cache_path = \"/mnt/lustre/work/oh/arubinstein17/cache\"\n",
    "cub_dir = os.path.join(cache_path, \"CUB_200_2011\", \"CUB_200_2011\")\n",
    "places_dir = os.path.join(cache_path, \"Places\", \"train\", \"data_large\")\n",
    "output_dir = os.path.join(cache_path, \"Waterbirds\", \"FG-Only\")\n",
    "dataset_name = 'waterbirds_birds_places'\n",
    "\n",
    "target_places = [\n",
    "    ['bamboo_forest', 'forest/broadleaf'],  # Land backgrounds\n",
    "    ['ocean', 'lake/natural']]              # Water backgrounds\n",
    "\n",
    "val_frac = 0.2             # What fraction of the training data to use as validation\n",
    "confounder_strength = 0.95 # Determines relative size of majority vs. minority groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation(mask):\n",
    "    contours, hierarchy = cv2.findContours((mask[:, :, 0]).astype(np.uint8), cv2.RETR_TREE,\n",
    "                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    segmentation = []\n",
    "\n",
    "    for contour in contours:\n",
    "        contour = contour.flatten().tolist()\n",
    "        # segmentation.append(contour)\n",
    "        if len(contour) > 4:\n",
    "            segmentation.append(contour)\n",
    "    return segmentation\n",
    "\n",
    "def make_symlink_cmd(src, dst):\n",
    "    symlink_cmd = (\n",
    "        f\"ln -s \"\n",
    "        f\"'{src}' \"\n",
    "        f\"{dst}\"\n",
    "    )\n",
    "    return symlink_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(cub_dir, 'images.txt')\n",
    "\n",
    "df = pd.read_csv(\n",
    "    images_path,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'img_filename'],\n",
    "    index_col='img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up labels of waterbirds vs. landbirds\n",
    "# We consider water birds = seabirds and waterfowl.\n",
    "species = np.unique([img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']])\n",
    "water_birds_list = [\n",
    "    'Albatross', # Seabirds\n",
    "    'Auklet',\n",
    "    'Cormorant',\n",
    "    'Frigatebird',\n",
    "    'Fulmar',\n",
    "    'Gull',\n",
    "    'Jaeger',\n",
    "    'Kittiwake',\n",
    "    'Pelican',\n",
    "    'Puffin',\n",
    "    'Tern',\n",
    "    'Gadwall', # Waterfowl\n",
    "    'Grebe',\n",
    "    'Mallard',\n",
    "    'Merganser',\n",
    "    'Guillemot',\n",
    "    'Pacific_Loon'\n",
    "]\n",
    "\n",
    "\n",
    "water_birds = {}\n",
    "for species_name in species:\n",
    "    water_birds[species_name] = 0\n",
    "    for water_bird in water_birds_list:\n",
    "        if water_bird.lower() in species_name:\n",
    "            water_birds[species_name] = 1\n",
    "species_list = [img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']]\n",
    "df['y'] = [water_birds[species] for species in species_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df =  pd.read_csv(\n",
    "    os.path.join(cub_dir, 'train_test_split.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'split'],\n",
    "    index_col='img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(train_test_df, on='img_id')\n",
    "test_ids = df.loc[df['split'] == 0].index\n",
    "train_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "val_ids = np.random.choice(\n",
    "    train_ids,\n",
    "    size=int(np.round(val_frac * len(train_ids))),\n",
    "    replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[train_ids, 'split'] = 0\n",
    "df.loc[val_ids, 'split'] = 1\n",
    "df.loc[test_ids, 'split'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['place'] = 0\n",
    "train_ids = np.array(df.loc[df['split'] == 0].index)\n",
    "val_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "test_ids = np.array(df.loc[df['split'] == 2].index)\n",
    "for split_idx, ids in enumerate([train_ids, val_ids, test_ids]):\n",
    "    for y in (0, 1):\n",
    "        if split_idx == 0: # train\n",
    "            if y == 0:\n",
    "                pos_fraction = 1 - confounder_strength\n",
    "            else:\n",
    "                pos_fraction = confounder_strength\n",
    "        else:\n",
    "            pos_fraction = 0.5\n",
    "        subset_df = df.loc[ids, :]\n",
    "        y_ids = np.array((subset_df.loc[subset_df['y'] == y]).index)\n",
    "        pos_place_ids = np.random.choice(\n",
    "            y_ids,\n",
    "            size=int(np.round(pos_fraction * len(y_ids))),\n",
    "            replace=False)\n",
    "        df.loc[pos_place_ids, 'place'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "waterbirds are 0.229 of the examples\n",
      "y = 0, c = 0: 0.950, n = 3513\n",
      "y = 0, c = 1: 0.050, n = 185\n",
      "y = 1, c = 0: 0.050, n = 55\n",
      "y = 1, c = 1: 0.950, n = 1042\n",
      "val:\n",
      "waterbirds are 0.235 of the examples\n",
      "y = 0, c = 0: 0.501, n = 459\n",
      "y = 0, c = 1: 0.499, n = 458\n",
      "y = 1, c = 0: 0.500, n = 141\n",
      "y = 1, c = 1: 0.500, n = 141\n",
      "test:\n",
      "waterbirds are 0.222 of the examples\n",
      "y = 0, c = 0: 0.500, n = 2255\n",
      "y = 0, c = 1: 0.500, n = 2255\n",
      "y = 1, c = 0: 0.500, n = 642\n",
      "y = 1, c = 1: 0.500, n = 642\n"
     ]
    }
   ],
   "source": [
    "for split, split_label in [(0, 'train'), (1, 'val'), (2, 'test')]:\n",
    "    print(f\"{split_label}:\")\n",
    "    split_df = df.loc[df['split'] == split, :]\n",
    "    print(f\"waterbirds are {np.mean(split_df['y']):.3f} of the examples\")\n",
    "    print(f\"y = 0, c = 0: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 0, c = 1: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 1))}\")\n",
    "    print(f\"y = 1, c = 0: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 1, c = 1: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_ids_df = pd.read_csv(\n",
    "    os.path.join(places_dir, 'categories_places365.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['place_name', 'place_id'],\n",
    "    index_col='place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bamboo_forest /b/bamboo_forest\n",
      "train category 0 /b/bamboo_forest has id 36\n",
      "forest/broadleaf /f/forest/broadleaf\n",
      "train category 0 /f/forest/broadleaf has id 36\n",
      "ocean /o/ocean\n",
      "train category 1 /o/ocean has id 150\n",
      "lake/natural /l/lake/natural\n",
      "train category 1 /l/lake/natural has id 150\n"
     ]
    }
   ],
   "source": [
    "target_place_ids = []\n",
    "\n",
    "for idx, target_places in enumerate(target_places):\n",
    "    place_filenames = []\n",
    "\n",
    "    for target_place in target_places:\n",
    "        target_place_full = f'/{target_place[0]}/{target_place}'\n",
    "        print(target_place, target_place_full)\n",
    "        assert (np.sum(place_ids_df['place_name'] == target_place_full) == 1)\n",
    "        target_place_ids.append(place_ids_df.index[place_ids_df['place_name'] == target_place_full][0])\n",
    "        print(f'train category {idx} {target_place_full} has id {target_place_ids[idx]}')\n",
    "\n",
    "        place_filenames += [\n",
    "            f'/{target_place[0]}/{target_place}/{filename}' for filename in os.listdir(\n",
    "                os.path.join(places_dir, target_place[0], target_place))\n",
    "            if filename.endswith('.jpg')]\n",
    "\n",
    "    random.shuffle(place_filenames)\n",
    "\n",
    "    # Assign each filename to an image\n",
    "    indices = (df.loc[:, 'place'] == idx)\n",
    "    assert len(place_filenames) >= np.sum(indices),\\\n",
    "        f\"Not enough places ({len(place_filenames)}) to fit the dataset ({np.sum(df.loc[:, 'place'] == idx)})\"\n",
    "    df.loc[indices, 'place_filename'] = place_filenames[:np.sum(indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Waterbirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_subfolder = os.path.join(output_dir, dataset_name)\n",
    "os.makedirs(output_subfolder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(output_subfolder, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11788/11788 [09:03<00:00, 21.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_instances = []\n",
    "test_instances = []\n",
    "val_instances = []\n",
    "\n",
    "for i in tqdm(df.index):\n",
    "    # Load bird image and segmentation\n",
    "    img_path = os.path.join(cub_dir, 'images', df.loc[i, 'img_filename'])\n",
    "    seg_path = os.path.join(cub_dir, 'segmentations', df.loc[i, 'img_filename'].replace('.jpg','.png'))\n",
    "    img_np = np.asarray(Image.open(img_path).convert('RGB'))\n",
    "    seg_np = np.asarray(Image.open(seg_path).convert('RGB')) / 255\n",
    "\n",
    "\n",
    "    place_path = os.path.join(places_dir, df.loc[i, 'place_filename'][1:])\n",
    "    place = Image.open(place_path).convert('RGB')\n",
    "\n",
    "    img_black = Image.fromarray(np.around(img_np * seg_np).astype(np.uint8))\n",
    "    combined_img = combine_and_mask(place, seg_np, img_black)\n",
    "    bird_img = combine_and_mask(Image.fromarray(np.ones_like(place) * 150), seg_np, img_black)\n",
    "\n",
    "    seg_np *= 0.\n",
    "    img_black = Image.fromarray(np.around(img_np * seg_np).astype(np.uint8))\n",
    "    place_img = combine_and_mask(place, seg_np * 0, img_black)\n",
    "\n",
    "    combined_path = os.path.join(output_subfolder, \"combined\", df.loc[i, 'img_filename'])\n",
    "    bird_path = os.path.join(output_subfolder, \"birds\", df.loc[i, 'img_filename'])\n",
    "    place_path = os.path.join(output_subfolder, \"places\", df.loc[i, 'img_filename'])\n",
    "\n",
    "    os.makedirs('/'.join(combined_path.split('/')[:-1]), exist_ok=True)\n",
    "    os.makedirs('/'.join(bird_path.split('/')[:-1]), exist_ok=True)\n",
    "    os.makedirs('/'.join(place_path.split('/')[:-1]), exist_ok=True)\n",
    "\n",
    "    combined_img.save(combined_path)\n",
    "    bird_img.save(bird_path)\n",
    "    place_img.save(place_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATERBIRDS_BASE_PATH = \"/mnt/lustre/work/oh/arubinstein17/cache/Waterbirds\"\n",
    "# /mnt/lustre/work/oh/arubinstein17/cache/Waterbirds/FG-Only/waterbirds_birds_places/birds\n",
    "FG_ONLY_PATH = os.path.join(WATERBIRDS_BASE_PATH, \"FG-Only\")\n",
    "ONLY_BIRDS_WB_PATH = os.path.join(FG_ONLY_PATH, \"waterbirds_birds_places\", \"birds\")\n",
    "WATERBIRDS_FG_BASE_PATH = os.path.join(FG_ONLY_PATH, \"test_split\")\n",
    "CLASSIC_WB_PATH = os.path.join(WATERBIRDS_BASE_PATH, \"waterbird_complete95_forest2water2\")\n",
    "\n",
    "wb_df = pd.read_csv(os.path.join(CLASSIC_WB_PATH, \"metadata.csv\"))\n",
    "wb_df[\"groups\"] = wb_df[\"y\"] * len(wb_df[\"place\"].unique()) + wb_df[\"place\"]\n",
    "test_df = wb_df[wb_df[\"split\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2255/2255 [00:07<00:00, 286.38it/s]\n",
      "100%|██████████| 2255/2255 [00:07<00:00, 302.93it/s]\n",
      "100%|██████████| 642/642 [00:02<00:00, 304.86it/s]\n",
      "100%|██████████| 642/642 [00:02<00:00, 283.08it/s]\n"
     ]
    }
   ],
   "source": [
    "df = test_df\n",
    "num_groups = len(df[\"groups\"].unique())\n",
    "num_classes = len(df[\"y\"].unique())\n",
    "\n",
    "base_path = WATERBIRDS_FG_BASE_PATH\n",
    "\n",
    "for group_id in range(num_groups):\n",
    "    dataset_path = os.path.join(base_path, \"group_\" + str(group_id))\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    folders = []\n",
    "    for label in range(num_classes):\n",
    "        cur_folder = os.path.join(dataset_path, str(label))\n",
    "        os.makedirs(cur_folder, exist_ok=True)\n",
    "        folders.append(cur_folder)\n",
    "\n",
    "    filtered_values = [\n",
    "        (row[\"img_filename\"], row[\"y\"])\n",
    "        for _, row in df.iterrows()\n",
    "        if row[\"groups\"] == group_id\n",
    "    ]\n",
    "\n",
    "    # make symlinks\n",
    "    for img_filename, y in tqdm(filtered_values):\n",
    "\n",
    "        parent_dir = os.path.dirname(img_filename)\n",
    "        base_name = os.path.basename(img_filename)\n",
    "        final_name = f\"{parent_dir}_{base_name}.jpg\"\n",
    "        symlink_cmd = make_symlink_cmd(\n",
    "            # os.path.join(CLASSIC_WB_PATH, img_filename),\n",
    "            os.path.join(ONLY_BIRDS_WB_PATH, img_filename),\n",
    "            os.path.join(folders[y], final_name)\n",
    "        )\n",
    "        os.system(symlink_cmd)\n",
    "\n",
    "    # clean empty class folders\n",
    "    for folder in folders:\n",
    "        if len(os.listdir(folder)) == 0:\n",
    "            shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"/mnt/lustre/work/oh/arubinstein17/cache/Waterbirds/FG-Only/test_split/group_0/0/200.Common_Yellowthroat_Common_Yellowthroat_0125_190902.jpg.jpg\").convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"/mnt/lustre/work/oh/arubinstein17/cache/Waterbirds/test_split/group_0/0/200.Common_Yellowthroat_Common_Yellowthroat_0125_190902.jpg.jpg\").convert('RGB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
